{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNTiNz41B9nyoHwCvHb5pjL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BobSheehan23/Bob_EquiLend_Models/blob/main/Heavil_Shorted_YTD_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. Load Data & Initial Setup ---\n",
        "# We begin by loading the dataset. The 'business_date' column is parsed as a date object,\n",
        "# which is crucial for time-series analysis. This ensures that we can correctly identify\n",
        "# the start and end of the period for calculations like Year-to-Date returns.\n",
        "try:\n",
        "    df = pd.read_csv('R3K_SecLending_after_20241231_clean.csv', parse_dates=['business_date'])\n",
        "    print(\"Step 1: Data loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'R3K_SecLending_after_20241231_clean.csv' not found.\")\n",
        "    print(\"Please ensure the CSV file is in the same directory as this notebook.\")\n",
        "    # Exit or create a dummy dataframe to avoid further errors in the script\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "if not df.empty:\n",
        "    # --- 2. Calculate Value-Based Utilization ---\n",
        "    # Value-Based Utilization is a key metric in securities lending that indicates how much of\n",
        "    # a security's available inventory is being borrowed. It's calculated as the ratio of\n",
        "    # the value of borrowed shares to the total inventory value.\n",
        "    # We convert 'borrow_value' and 'inventory_val_amt' to numeric types, coercing any\n",
        "    # errors into 'Not a Number' (NaN). This prevents non-numeric data from breaking our calculations.\n",
        "    # Rows with missing essential data for this calculation are dropped to ensure data quality.\n",
        "    # To handle cases where inventory value is zero (which would cause a division by zero error),\n",
        "    # we replace the resulting 'infinity' values with NaN.\n",
        "    df['borrow_value'] = pd.to_numeric(df['borrow_value'], errors='coerce')\n",
        "    df['inventory_val_amt'] = pd.to_numeric(df['inventory_val_amt'], errors='coerce')\n",
        "    df.dropna(subset=['borrow_value', 'inventory_val_amt'], inplace=True)\n",
        "    df['utilization'] = df['borrow_value'] / df['inventory_val_amt']\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    print(\"Step 2: Value-Based Utilization calculated.\")\n",
        "\n",
        "    # --- 3. Apply Value-Based Gating ---\n",
        "    # To focus our analysis on securities with significant lending activity, we apply a 'gating'\n",
        "    # procedure. This filters the universe of stocks to include only those that meet certain\n",
        "    # criteria on the most recent trading day in the dataset. This ensures our analysis is\n",
        "    # focused on relevant, actively lent names.\n",
        "    latest_date = df['business_date'].max()\n",
        "    latest_day_data = df[df['business_date'] == latest_date]\n",
        "\n",
        "    gating_criteria = (latest_day_data['borrow_value'] >= 1_000_000) & \\\n",
        "                      (latest_day_data['inventory_val_amt'] >= 10_000_000)\n",
        "\n",
        "    gated_tickers = latest_day_data[gating_criteria]['ticker'].unique()\n",
        "    gated_df = df[df['ticker'].isin(gated_tickers)].copy()\n",
        "    print(f\"Step 3: Gating applied. {len(gated_tickers)} stocks met the criteria.\")\n",
        "\n",
        "    # --- 4. Calculate YTD Returns & Average Utilization ---\n",
        "    # For the gated stocks, we now calculate Year-to-Date (YTD) returns and average utilization.\n",
        "    # YTD return is calculated as the percentage change in price from the first to the last\n",
        "    # day of the period for each stock. Average utilization is the mean of the daily\n",
        "    # utilization over the entire period. These two metrics will be the basis of our analysis.\n",
        "    gated_df.sort_values(by=['ticker', 'business_date'], inplace=True)\n",
        "\n",
        "    # Calculate YTD returns\n",
        "    start_prices = gated_df.groupby('ticker')['security_price'].first()\n",
        "    end_prices = gated_df.groupby('ticker')['security_price'].last()\n",
        "    ytd_returns = ((end_prices - start_prices) / start_prices)\n",
        "    ytd_returns.name = 'ytd_return'\n",
        "\n",
        "    # Calculate average utilization\n",
        "    avg_utilization = gated_df.groupby('ticker')['utilization'].mean()\n",
        "    avg_utilization.name = 'avg_utilization'\n",
        "\n",
        "    # Combine into a single analysis DataFrame\n",
        "    analysis_df = pd.concat([ytd_returns, avg_utilization], axis=1)\n",
        "    analysis_df.dropna(inplace=True) # Drop stocks with missing data for these metrics\n",
        "    print(\"Step 4: YTD Returns and Average Utilization calculated.\")\n",
        "    print(\"\\nSample of the analysis DataFrame:\")\n",
        "    print(analysis_df.head())\n",
        "\n",
        "\n",
        "    # --- 5. Decile Analysis ---\n",
        "    # To understand the relationship between utilization and performance, we perform a decile analysis.\n",
        "    # Stocks are sorted by their average utilization and then grouped into ten equal-sized buckets (deciles).\n",
        "    # We then calculate the mean YTD return for each decile. This may indicate if\n",
        "    # higher utilization is associated with different return profiles.\n",
        "    analysis_df['decile'] = pd.qcut(analysis_df['avg_utilization'], 10, labels=False, duplicates='drop')\n",
        "    decile_analysis = analysis_df.groupby('decile')['ytd_return'].agg(['mean'])\n",
        "    print(\"\\n--- Step 5: Decile Analysis ---\")\n",
        "    print(\"Mean YTD Return by Utilization Decile:\")\n",
        "    print(decile_analysis)\n",
        "\n",
        "\n",
        "    # --- 6. Extreme Group Analysis ---\n",
        "    # This analysis focuses on the extremes. We look at the performance of the top and bottom 50\n",
        "    # stocks by average utilization, as well as the top and bottom 1%. This can highlight\n",
        "    # performance characteristics of the most and least crowded shorts in the market.\n",
        "    # This may provide signals about market sentiment at its extremes.\n",
        "    print(\"\\n--- Step 6: Extreme Group Analysis ---\")\n",
        "    sorted_analysis_df = analysis_df.sort_values(by='avg_utilization', ascending=False)\n",
        "\n",
        "    # Top and Bottom 50 Analysis\n",
        "    top_50 = sorted_analysis_df.head(50)\n",
        "    bottom_50 = sorted_analysis_df.tail(50)\n",
        "\n",
        "    print(\"\\nPerformance of Top 50 Stocks by Average Utilization:\")\n",
        "    print(top_50['ytd_return'].agg(['mean']))\n",
        "\n",
        "    print(\"\\nPerformance of Bottom 50 Stocks by Average Utilization:\")\n",
        "    print(bottom_50['ytd_return'].agg(['mean']))\n",
        "\n",
        "\n",
        "    # Top and Bottom 1% Analysis\n",
        "    # This is performed only if the gated universe is large enough to yield meaningful results.\n",
        "    num_stocks = len(analysis_df)\n",
        "    if num_stocks >= 100:\n",
        "        one_percent_count = int(num_stocks * 0.01)\n",
        "        if one_percent_count > 0:\n",
        "            top_1_percent = sorted_analysis_df.head(one_percent_count)\n",
        "            bottom_1_percent = sorted_analysis_df.tail(one_percent_count)\n",
        "\n",
        "            print(f\"\\nPerformance of Top 1% ({one_percent_count} stocks) by Average Utilization:\")\n",
        "            print(top_1_percent['ytd_return'].agg(['mean']))\n",
        "\n",
        "            print(f\"\\nPerformance of Bottom 1% ({one_percent_count} stocks) by Average Utilization:\")\n",
        "            print(bottom_1_percent['ytd_return'].agg(['mean']))\n",
        "        else:\n",
        "            print(\"\\nNot enough stocks for a meaningful 1% analysis (1% is less than 1 stock).\")\n",
        "    else:\n",
        "        print(\"\\nSkipping 1% analysis because there are fewer than 100 stocks in the gated universe.\")"
      ],
      "metadata": {
        "id": "UkPB4pAyMpPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OAyUu_mvMr34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "746ca5b2"
      },
      "source": [
        "# Task\n",
        "Generate a market flash document titled \"Market Flash: Most Shorted Stocks\" that includes the provided text and two bar charts visualizing the decile analysis and extreme group analysis of stock returns based on utilization rates. The charts should replace the tables in the original analysis. Use the data from the `decile_analysis` DataFrame for the decile chart and the calculated mean YTD returns for the extreme groups (Top 50, Bottom 50, Top 1%, Bottom 1%) for the extreme group chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c18553fd"
      },
      "source": [
        "## Visualize decile analysis\n",
        "\n",
        "### Subtask:\n",
        "Create a bar chart showing the mean YTD return for each utilization decile based on the `decile_analysis` DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e967db5"
      },
      "source": [
        "**Reasoning**:\n",
        "Generate a bar chart to visualize the mean YTD return for each utilization decile using the `decile_analysis` DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51936665"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Chart Colors ---\n",
        "text_color = '#374151'\n",
        "title_color = '#006db7'\n",
        "negative_color = '#f57600'\n",
        "positive_color = '#048dd2'\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Assign colors based on whether the mean return is negative or positive\n",
        "colors = [negative_color if mean < 0 else positive_color for mean in decile_analysis['mean']]\n",
        "plt.bar(decile_analysis.index, decile_analysis['mean'], color=colors)\n",
        "\n",
        "\n",
        "plt.xlabel('Utilization Decile', fontsize=12, fontweight='bold', color=text_color)\n",
        "plt.ylabel('Mean YTD Return', fontsize=12, fontweight='bold', color=text_color)\n",
        "plt.title('Mean YTD Return by Utilization Decile', fontsize=14, fontweight='bold', color=title_color)\n",
        "plt.xticks(decile_analysis.index)\n",
        "plt.yticks(color=text_color, fontweight='bold')\n",
        "# Remove gridlines\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6684a90f"
      },
      "source": [
        "## Visualize extreme group analysis\n",
        "\n",
        "### Subtask:\n",
        "Create a bar chart comparing the mean YTD returns of the Top 50, Bottom 50, Top 1%, and Bottom 1% groups based on the previously printed analysis results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd0bf1ca"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a bar chart to visualize the mean YTD returns for the extreme utilization groups using the previously calculated values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d837ba7f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract mean returns for extreme groups from previous analysis output\n",
        "extreme_group_returns = {\n",
        "    \"Top 50\": top_50['ytd_return'].mean(),\n",
        "    \"Bottom 50\": bottom_50['ytd_return'].mean(),\n",
        "    \"Top 1%\": top_1_percent['ytd_return'].mean(),\n",
        "    \"Bottom 1%\": bottom_1_percent['ytd_return'].mean()\n",
        "}\n",
        "\n",
        "labels = list(extreme_group_returns.keys())\n",
        "returns = list(extreme_group_returns.values())\n",
        "\n",
        "# --- Chart Colors ---\n",
        "text_color = '#374151'\n",
        "title_color = '#006db7'\n",
        "colors = ['#048dd2', '#f57600', '#048dd2', '#f57600'] # Using provided colors for bars\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(labels, returns, color=colors)\n",
        "plt.xlabel('Group', fontsize=12, fontweight='bold', color=text_color)\n",
        "plt.ylabel('Mean YTD Return', fontsize=12, fontweight='bold', color=text_color)\n",
        "plt.title('Mean YTD Return for Extreme Utilization Groups', fontsize=14, fontweight='bold', color=title_color)\n",
        "plt.yticks(color=text_color, fontweight='bold')\n",
        "# Remove gridlines\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cce7d2c"
      },
      "source": [
        "## Combine text and charts\n",
        "\n",
        "### Subtask:\n",
        "Create a markdown cell that includes the provided market flash text and the generated charts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a00bdcf4"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a markdown cell with the market flash text and the previously generated charts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfa598c8"
      },
      "source": [
        "%%markdown\n",
        "# Market Flash: Most Shorted Stocks\n",
        "\n",
        "This market flash analyzes the relationship between stock utilization rates (a proxy for short interest) and Year-to-Date (YTD) stock returns for a universe of stocks that meet certain value-based gating criteria as of the most recent trading day in the dataset (July 25, 2025).\n",
        "\n",
        "The analysis focuses on two key aspects:\n",
        "1.  **Decile Analysis:** Examining the mean YTD return for stocks grouped into deciles based on their average utilization rate over the period.\n",
        "2.  **Extreme Group Analysis:** Comparing the mean YTD returns of the top and bottom 50 stocks, as well as the top and bottom 1% of stocks by average utilization.\n",
        "\n",
        "## Decile Analysis: Mean YTD Return by Utilization Decile\n",
        "\n",
        "The chart below illustrates the mean YTD return for each decile of utilization. We see a general trend where higher utilization deciles tend to exhibit higher mean YTD returns, with a significant jump in performance for the highest decile.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d001877"
      },
      "source": [
        "**Reasoning**:\n",
        "Continue adding the remaining text and the extreme group analysis chart to the markdown cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53c291bd"
      },
      "source": [
        "%%markdown\n",
        "# Market Flash: Most Shorted Stocks\n",
        "\n",
        "This market flash analyzes the relationship between stock utilization rates (a proxy for short interest) and Year-to-Date (YTD) stock returns for a universe of stocks that meet certain value-based gating criteria as of the most recent trading day in the dataset (July 25, 2025).\n",
        "\n",
        "The analysis focuses on two key aspects:\n",
        "1.  **Decile Analysis:** Examining the mean YTD return for stocks grouped into deciles based on their average utilization rate over the period.\n",
        "2.  **Extreme Group Analysis:** Comparing the mean YTD returns of the top and bottom 50 stocks, as well as the top and bottom 1% of stocks by average utilization.\n",
        "\n",
        "## Decile Analysis: Mean YTD Return by Utilization Decile\n",
        "\n",
        "The chart below illustrates the mean YTD return for each decile of utilization. We see a general trend where higher utilization deciles tend to exhibit higher mean YTD returns, with a significant jump in performance for the highest decile.\n",
        "\n",
        "## Extreme Group Analysis: Mean YTD Return for Extreme Utilization Groups\n",
        "\n",
        "The chart below compares the mean YTD returns for stocks in the top and bottom 50, and top and bottom 1% of average utilization. This analysis confirms the trend observed in the decile analysis, with the highest utilization groups showing significantly higher mean YTD returns compared to the lowest utilization groups.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9694d544"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The analysis shows a general trend where higher stock utilization deciles tend to have higher mean Year-to-Date (YTD) returns.\n",
        "*   There is a significant increase in mean YTD return for the highest utilization decile.\n",
        "*   Comparing extreme groups, the highest utilization groups (Top 50 and Top 1%) exhibit significantly higher mean YTD returns compared to the lowest utilization groups (Bottom 50 and Bottom 1%).\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The positive correlation between utilization rate and YTD return suggests a potential \"short squeeze\" effect or that highly utilized stocks are experiencing strong positive momentum.\n",
        "*   Further analysis could investigate the drivers behind the strong performance of the highest utilization deciles and extreme groups, such as news events, sector concentration, or market sentiment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad1b86dd"
      },
      "source": [
        "# Market Flash: Most Shorted Stocks\n",
        "\n",
        "**Heavily Shorted Stocks Significantly Outperforming YTD**\n",
        "\n",
        "Our analysis of the R3K Securities Lending data for the period after December 31, 2024, reveals a strong correlation between high average utilization rates (a proxy for shorting activity) and Year-to-Date (YTD) stock returns.\n",
        "\n",
        "**Key Findings:**\n",
        "\n",
        "**Decile Analysis:**\n",
        "\n",
        "*   Stocks in the highest utilization decile (Decile 10) have shown a remarkable Mean YTD Return of 21.8%. This is significantly higher than the returns observed in lower utilization deciles.\n",
        "*   Conversely, lower utilization deciles generally exhibit lower mean and median YTD returns. For example, Decile 1 (lowest utilization) has a Mean YTD Return of 3.7%.\n",
        "\n",
        "## Decile Analysis: Mean YTD Return by Utilization Decile\n",
        "\n",
        "<!-- The chart for Mean YTD Return by Utilization Decile will be inserted here -->\n",
        "\n",
        "**Extreme Group Analysis:**\n",
        "\n",
        "*   The Top 50 Most Shorted stocks (based on average utilization) have experienced an impressive Mean YTD Return of 27.1% and a Median YTD Return of 2.5%.\n",
        "*    In stark contrast, the Bottom 50 Least Shorted stocks have only yielded a Mean YTD Return of 5.3% and a Median YTD Return of 2.0%.\n",
        "*   Looking at the most extreme cases, the Top 1% Most Shorted stocks (25 stocks) still show a strong Mean YTD Return of 11.9%. The Bottom 1% Least Shorted stocks (25 stocks) have a Mean YTD Return of 3.9%.\n",
        "\n",
        "## Extreme Group Analysis: Mean YTD Return for Extreme Utilization Groups\n",
        "\n",
        "<!-- The chart for Mean YTD Return for Extreme Utilization Groups will be inserted here -->\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "The substantial outperformance of stocks with high average utilization rates, particularly in the top decile and the top 50 most shorted, strongly suggests that short sellers in these stocks have been under pressure. This pressure could be due to a variety of factors, including unexpected positive news, strong market momentum, or coordinated buying activity, forcing short sellers to buy back shares to cover their positions, thus driving prices up further.\n",
        "\n",
        "The difference in returns between the most and least shorted groups is significant and warrants attention from market participants. This pattern is consistent with a short squeeze scenario, where high short interest fuels upward price momentum as short sellers are forced to cover their positions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae902f11"
      },
      "source": [
        "## Market Flash: Most Shorted Stocks\n",
        "\n",
        "**Heavily Shorted Stocks Significantly Outperforming YTD**\n",
        "\n",
        "Our analysis of the R3K Securities Lending data for the period after December 31, 2024, reveals a strong correlation between high average utilization rates (a proxy for shorting activity) and Year-to-Date (YTD) stock returns.\n",
        "\n",
        "**Key Findings:**\n",
        "\n",
        "**Decile Analysis:**\n",
        "\n",
        "*   Stocks in the highest utilization decile (Decile 10) have shown a remarkable Mean YTD Return of 21.8%. This is significantly higher than the returns observed in lower utilization deciles.\n",
        "*   Conversely, lower utilization deciles generally exhibit lower mean and median YTD returns. For example, Decile 1 (lowest utilization) has a Mean YTD Return of 3.7%.\n",
        "\n",
        "## Decile Analysis: Mean YTD Return by Utilization Decile\n",
        "\n",
        "{cell_id:51936665}\n",
        "\n",
        "**Extreme Group Analysis:**\n",
        "\n",
        "*   The Top 50 Most Shorted stocks (based on average utilization) have experienced an impressive Mean YTD Return of 27.1% and a Median YTD Return of 2.5%.\n",
        "*    In stark contrast, the Bottom 50 Least Shorted stocks have only yielded a Mean YTD Return of 5.3% and a Median YTD Return of 2.0%.\n",
        "*   Looking at the most extreme cases, the Top 1% Most Shorted stocks (25 stocks) still show a strong Mean YTD Return of 11.9%. The Bottom 1% Least Shorted stocks (25 stocks) have a Mean YTD Return of 3.9%.\n",
        "\n",
        "## Extreme Group Analysis: Mean YTD Return for Extreme Utilization Groups\n",
        "\n",
        "{cell_id:d837ba7f}\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "The substantial outperformance of stocks with high average utilization rates, particularly in the top decile and the top 50 most shorted, strongly suggests that short sellers in these stocks have been under pressure. This pressure could be due to a variety of factors, including unexpected positive news, strong market momentum, or coordinated buying activity, forcing short sellers to buy back shares to cover their positions, thus driving prices up further.\n",
        "\n",
        "The difference in returns between the most and least shorted groups is significant and warrants attention from market participants. This pattern is consistent with a short squeeze scenario, where high short interest fuels upward price momentum as short sellers are forced to cover their positions."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. Load Data & Initial Setup ---\n",
        "# We begin by loading the dataset. The 'business_date' column is parsed as a date object,\n",
        "# which is crucial for time-series analysis. This ensures that we can correctly identify\n",
        "# the start and end of the period for calculations like Year-to-Date returns.\n",
        "try:\n",
        "    df = pd.read_csv('R3K_SecLending_after_20241231_clean.csv', parse_dates=['business_date'])\n",
        "    print(\"Step 1: Data loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'R3K_SecLending_after_20241231_clean.csv' not found.\")\n",
        "    print(\"Please ensure the CSV file is in the same directory as this notebook.\")\n",
        "    # Exit or create a dummy dataframe to avoid further errors in the script\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "if not df.empty:\n",
        "    # --- 2. Calculate Value-Based Utilization ---\n",
        "    # Value-Based Utilization is a key metric in securities lending that indicates how much of\n",
        "    # a security's available inventory is being borrowed. It's calculated as the ratio of\n",
        "    # the value of borrowed shares to the total inventory value.\n",
        "    # We convert 'borrow_value' and 'inventory_val_amt' to numeric types, coercing any\n",
        "    # errors into 'Not a Number' (NaN). This prevents non-numeric data from breaking our calculations.\n",
        "    # Rows with missing essential data for this calculation are dropped to ensure data quality.\n",
        "    # To handle cases where inventory value is zero (which would cause a division by zero error),\n",
        "    # we replace the resulting 'infinity' values with NaN.\n",
        "    df['borrow_value'] = pd.to_numeric(df['borrow_value'], errors='coerce')\n",
        "    df['inventory_val_amt'] = pd.to_numeric(df['inventory_val_amt'], errors='coerce')\n",
        "    df.dropna(subset=['borrow_value', 'inventory_val_amt'], inplace=True)\n",
        "    df['utilization'] = df['borrow_value'] / df['inventory_val_amt']\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    print(\"Step 2: Value-Based Utilization calculated.\")\n",
        "\n",
        "    # --- 3. Apply Value-Based Gating ---\n",
        "    # To focus our analysis on securities with significant lending activity, we apply a 'gating'\n",
        "    # procedure. This filters the universe of stocks to include only those that meet certain\n",
        "    # criteria on the most recent trading day in the dataset. This ensures our analysis is\n",
        "    # focused on relevant, actively lent names.\n",
        "    latest_date = df['business_date'].max()\n",
        "    latest_day_data = df[df['business_date'] == latest_date]\n",
        "\n",
        "    gating_criteria = (latest_day_data['borrow_value'] >= 1_000_000) & \\\n",
        "                      (latest_day_data['inventory_val_amt'] >= 10_000_000)\n",
        "\n",
        "    gated_tickers = latest_day_data[gating_criteria]['ticker'].unique()\n",
        "    gated_df = df[df['ticker'].isin(gated_tickers)].copy()\n",
        "    print(f\"Step 3: Gating applied. {len(gated_tickers)} stocks met the criteria.\")\n",
        "\n",
        "    # --- 4. Calculate YTD Returns & Average Utilization ---\n",
        "    # For the gated stocks, we now calculate Year-to-Date (YTD) returns and average utilization.\n",
        "    # YTD return is calculated as the percentage change in price from the first to the last\n",
        "    # day of the period for each stock. Average utilization is the mean of the daily\n",
        "    # utilization over the entire period. These two metrics will be the basis of our analysis.\n",
        "    gated_df.sort_values(by=['ticker', 'business_date'], inplace=True)\n",
        "\n",
        "    # Calculate YTD returns\n",
        "    start_prices = gated_df.groupby('ticker')['security_price'].first()\n",
        "    end_prices = gated_df.groupby('ticker')['security_price'].last()\n",
        "    ytd_returns = ((end_prices - start_prices) / start_prices)\n",
        "    ytd_returns.name = 'ytd_return'\n",
        "\n",
        "    # Calculate average utilization\n",
        "    avg_utilization = gated_df.groupby('ticker')['utilization'].mean()\n",
        "    avg_utilization.name = 'avg_utilization'\n",
        "\n",
        "    # Combine into a single analysis DataFrame\n",
        "    analysis_df = pd.concat([ytd_returns, avg_utilization], axis=1)\n",
        "    analysis_df.dropna(inplace=True) # Drop stocks with missing data for these metrics\n",
        "    print(\"Step 4: YTD Returns and Average Utilization calculated.\")\n",
        "    print(\"\\nSample of the analysis DataFrame:\")\n",
        "    print(analysis_df.head())\n",
        "\n",
        "\n",
        "    # --- 5. Decile Analysis ---\n",
        "    # To understand the relationship between utilization and performance, we perform a decile analysis.\n",
        "    # Stocks are sorted by their average utilization and then grouped into ten equal-sized buckets (deciles).\n",
        "    # We then calculate the mean YTD return for each decile. This may indicate if\n",
        "    # higher utilization is associated with different return profiles.\n",
        "    analysis_df['decile'] = pd.qcut(analysis_df['avg_utilization'], 10, labels=False, duplicates='drop')\n",
        "    decile_analysis = analysis_df.groupby('decile')['ytd_return'].agg(['mean'])\n",
        "    print(\"\\n--- Step 5: Decile Analysis ---\")\n",
        "    print(\"Mean YTD Return by Utilization Decile:\")\n",
        "    print(decile_analysis)\n",
        "\n",
        "\n",
        "    # --- 6. Extreme Group Analysis ---\n",
        "    # This analysis focuses on the extremes. We look at the performance of the top and bottom 50\n",
        "    # stocks by average utilization, as well as the top and bottom 1%. This can highlight\n",
        "    # performance characteristics of the most and least crowded shorts in the market.\n",
        "    # This may provide signals about market sentiment at its extremes.\n",
        "    print(\"\\n--- Step 6: Extreme Group Analysis ---\")\n",
        "    sorted_analysis_df = analysis_df.sort_values(by='avg_utilization', ascending=False)\n",
        "\n",
        "    # Top and Bottom 50 Analysis\n",
        "    top_50 = sorted_analysis_df.head(50)\n",
        "    bottom_50 = sorted_analysis_df.tail(50)\n",
        "\n",
        "    print(\"\\nPerformance of Top 50 Stocks by Average Utilization:\")\n",
        "    print(top_50['ytd_return'].agg(['mean']))\n",
        "\n",
        "    print(\"\\nPerformance of Bottom 50 Stocks by Average Utilization:\")\n",
        "    print(bottom_50['ytd_return'].agg(['mean']))\n",
        "\n",
        "\n",
        "    # Top and Bottom 1% Analysis\n",
        "    # This is performed only if the gated universe is large enough to yield meaningful results.\n",
        "    num_stocks = len(analysis_df)\n",
        "    if num_stocks >= 100:\n",
        "        one_percent_count = int(num_stocks * 0.01)\n",
        "        if one_percent_count > 0:\n",
        "            top_1_percent = sorted_analysis_df.head(one_percent_count)\n",
        "            bottom_1_percent = sorted_analysis_df.tail(one_percent_count)\n",
        "\n",
        "            print(f\"\\nPerformance of Top 1% ({one_percent_count} stocks) by Average Utilization:\")\n",
        "            print(top_1_percent['ytd_return'].agg(['mean']))\n",
        "\n",
        "            print(f\"\\nPerformance of Bottom 1% ({one_percent_count} stocks) by Average Utilization:\")\n",
        "            print(bottom_1_percent['ytd_return'].agg(['mean']))\n",
        "        else:\n",
        "            print(\"\\nNot enough stocks for a meaningful 1% analysis (1% is less than 1 stock).\")\n",
        "    else:\n",
        "        print(\"\\nSkipping 1% analysis because there are fewer than 100 stocks in the gated universe.\")"
      ],
      "metadata": {
        "id": "jnCGNmzRP3Ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vDra0qjLP31k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cef0a50"
      },
      "source": [
        "### Top 50 Stocks by Average Utilization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e053b919"
      },
      "source": [
        "display(top_50['ytd_return'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6d9020b"
      },
      "source": [
        "### Bottom 50 Stocks by Average Utilization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9633730"
      },
      "source": [
        "display(bottom_50['ytd_return'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abe2cabc"
      },
      "source": [
        "### Top 1% Stocks by Average Utilization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d723276"
      },
      "source": [
        "display(top_1_percent['ytd_return'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45096b9d"
      },
      "source": [
        "### Bottom 1% Stocks by Average Utilization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cb48d70"
      },
      "source": [
        "display(bottom_1_percent['ytd_return'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c400f6b"
      },
      "source": [
        "# Methodology Document\n",
        "\n",
        "This document outlines the methodology used to analyze the relationship between stock utilization rates and Year-to-Date (YTD) stock returns based on the provided R3K Securities Lending data.\n",
        "\n",
        "## 1. Data Loading and Initial Setup\n",
        "\n",
        "*   The dataset is loaded from the CSV file 'R3K\\_SecLending\\_after\\_20241231\\_clean.csv'.\n",
        "*   The 'business\\_date' column is parsed as a date object to enable time-series analysis.\n",
        "*   Error handling is included to check for the presence of the data file.\n",
        "\n",
        "## 2. Calculation of Value-Based Utilization\n",
        "\n",
        "*   Value-Based Utilization is calculated as the ratio of 'borrow\\_value' to 'inventory\\_val\\_amt'.\n",
        "*   Both 'borrow\\_value' and 'inventory\\_val\\_amt' are converted to numeric types, with errors coerced to NaN.\n",
        "*   Rows with missing values in 'borrow\\_value' or 'inventory\\_val\\_amt' are removed.\n",
        "*   Infinite values resulting from division by zero are replaced with NaN.\n",
        "\n",
        "## 3. Application of Value-Based Gating\n",
        "\n",
        "*   The analysis is focused on stocks that meet specific criteria on the most recent trading day in the dataset.\n",
        "*   The gating criteria are: 'borrow\\_value' >= 1,000,000 and 'inventory\\_val\\_amt' >= 10,000,000.\n",
        "*   A list of tickers that meet these criteria is generated.\n",
        "*   The original DataFrame is filtered to include only the data for these gated tickers.\n",
        "\n",
        "## 4. Calculation of YTD Returns and Average Utilization\n",
        "\n",
        "*   The gated data is sorted by ticker and business date.\n",
        "*   YTD return for each stock is calculated as the percentage change in 'security\\_price' from the first to the last day of the period.\n",
        "*   Average utilization for each stock is calculated as the mean of the 'utilization' values over the period.\n",
        "*   YTD returns and average utilization are combined into a single analysis DataFrame.\n",
        "*   Stocks with missing data for either metric in the analysis DataFrame are removed.\n",
        "\n",
        "## 5. Decile Analysis\n",
        "\n",
        "*   Stocks in the analysis DataFrame are sorted by their average utilization.\n",
        "*   The sorted stocks are divided into ten equal-sized deciles based on average utilization.\n",
        "*   The mean YTD return is calculated for each utilization decile.\n",
        "\n",
        "## 6. Extreme Group Analysis\n",
        "\n",
        "*   The analysis DataFrame is sorted by average utilization in descending order.\n",
        "*   The top 50 and bottom 50 stocks by average utilization are identified.\n",
        "*   The top 1% and bottom 1% of stocks by average utilization are identified, provided there are at least 100 stocks in the analysis universe.\n",
        "*   The mean YTD return is calculated for each of these extreme groups (Top 50, Bottom 50, Top 1%, Bottom 1%)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d498f85"
      },
      "source": [
        "# Read the tickers from the Excel sheet\n",
        "holdings_df = pd.read_excel(\"/content/R3K_Holdings.xlsx\")\n",
        "excel_tickers = set(holdings_df['Ticker'].unique())\n",
        "\n",
        "# Get the tickers from the original CSV file\n",
        "# Assuming the original dataframe before gating is 'df'\n",
        "if not df.empty:\n",
        "    csv_tickers = set(df['ticker'].unique())\n",
        "\n",
        "    # Find the overlap\n",
        "    overlap_tickers = excel_tickers.intersection(csv_tickers)\n",
        "\n",
        "    print(f\"Number of tickers from the Excel sheet present in the original CSV file: {len(overlap_tickers)}\")\n",
        "else:\n",
        "    print(\"The original dataframe (df) is empty. Cannot determine overlap.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8qx5q2pESJoM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}