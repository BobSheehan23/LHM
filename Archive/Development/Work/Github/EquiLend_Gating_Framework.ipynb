{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "286aea82",
   "metadata": {},
   "source": [
    "# EquiLend Gating Framework Process & Overview\n",
    "\n",
    "A systematic, data-driven process designed to identify securities with the highest potential for short-squeeze risk through sequential filtering gates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7db7ba6",
   "metadata": {},
   "source": [
    "# Gating Framework: Thought Process, Research, and Overview\n",
    "\n",
    "## Overview\n",
    "The gating framework is a systematic, data-driven process designed to identify securities with the highest potential for short-squeeze risk. By applying a series of sequential filters (\"gates\"), the framework narrows down a broad universe of securities to a focused list of candidates that meet strict criteria for liquidity, demand, and risk factors.\n",
    "\n",
    "## Gate Sequence and Rationale\n",
    "1. **Initial Universe**: All securities in the dataset.\n",
    "2. **On-Loan Value ≥ $1M**: Ensures the security has a meaningful level of short interest, filtering out illiquid or inactive names.\n",
    "3. **Borrower Count ≥ 3**: Validates that short demand is broad-based and not driven by a single entity, reducing idiosyncratic risk.\n",
    "4. **Lender Count ≥ 2**: Ensures the supply side is not concentrated, reducing the risk of a single lender's actions creating a misleading signal.\n",
    "5. **Lendable Inventory > 10% of Float**: Confirms the security is part of the liquid lendable market, avoiding signals driven by artificially small supply.\n",
    "6. **Utilization ≥ 50%**: Focuses on names where lendable supply is significantly constrained, increasing squeeze potential.\n",
    "7. **Days to Cover ≥ 2**: Indicates it would take multiple days for shorts to exit positions, which can amplify a squeeze.\n",
    "\n",
    "## Float Calculation\n",
    "Float is a critical metric in the analysis, calculated as:\n",
    "\n",
    "    Float = On Loan Quantity / (Short Interest Indicator / 100)\n",
    "\n",
    "This approach ensures that the float reflects the true available supply in the market, accounting for both borrow activity and reported short interest.\n",
    "\n",
    "## Research & Thought Process\n",
    "- **Liquidity and Market Depth**: The initial gates focus on ensuring that only liquid, actively traded securities are considered, as these are more likely to experience meaningful price movements.\n",
    "- **Breadth of Demand and Supply**: By requiring a minimum number of borrowers and lenders, the framework avoids names where activity is dominated by a single participant, which could skew results or create false signals.\n",
    "- **Supply Constraints**: High utilization and low lendable inventory relative to float are classic indicators of potential squeezes, as they signal that shorts may struggle to cover positions if demand spikes or supply contracts.\n",
    "- **Exit Difficulty**: Days to cover is a direct measure of how hard it would be for shorts to unwind positions, with higher values indicating greater risk of a squeeze.\n",
    "\n",
    "## Summary\n",
    "This gating process is the result of research into market microstructure, historical short-squeeze events, and best practices in securities lending analytics. The framework is designed to be robust, transparent, and adaptable to evolving market conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d5cb2a",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/BobSheehan23/EquiLend/blob/main/EquiLend_Gating_Framework_Process_%26_Overview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3cbb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === Configuration ===\n",
    "MAIN_COLOR = '#006EB7'\n",
    "DATA_FILE_PATH = 'Daily_Data_Dispatch_2025-06-16_bsheehan_adhoc.csv'\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette([MAIN_COLOR])\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Analysis Date: {datetime.today().strftime('%B %d, %Y')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f13f78",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation\n",
    "\n",
    "This section loads the raw data and creates the derived metrics needed for the gating framework analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ccbdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(file_path):\n",
    "    \"\"\"\n",
    "    Load and prepare data for gating framework analysis.\n",
    "    Creates derived metrics including Float, Days to Cover, and Market Cap.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Successfully loaded {len(df):,} securities from {file_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "        return None\n",
    "    \n",
    "    # Rename columns for easier handling\n",
    "    column_mapping = {\n",
    "        'Utilization (%)': 'Utilization_Pct',\n",
    "        'On Loan Value (USD)': 'OnLoanValueUSD',\n",
    "        'Short Interest Indicator': 'ShortInterestPct',\n",
    "        'Total Lendable Value (USD)': 'LendableValueUSD',\n",
    "        'Security Price (USD)': 'PriceUSD',\n",
    "        'Borrower Count': 'BorrowerCount',\n",
    "        'Lender Count': 'LenderCount',\n",
    "        'Average Fee': 'AvgFee',\n",
    "        'On Loan Quantity': 'OnLoanQty',\n",
    "        'Composite 20-Day ADV': 'ADV20Day'\n",
    "    }\n",
    "    \n",
    "    df.rename(columns=column_mapping, inplace=True, errors='ignore')\n",
    "    \n",
    "    # Calculate derived metrics\n",
    "    df['Float'] = np.where(df['ShortInterestPct'] > 0, \n",
    "                          df['OnLoanQty'] / (df['ShortInterestPct'] / 100), 0)\n",
    "    \n",
    "    df['LendableShares'] = np.where(df['PriceUSD'] > 0, \n",
    "                                   df['LendableValueUSD'] / df['PriceUSD'], 0)\n",
    "    \n",
    "    df['LendablePctFloat'] = np.where(df['Float'] > 0, \n",
    "                                     (df['LendableShares'] / df['Float']) * 100, 0)\n",
    "    \n",
    "    df['DaysToCover'] = np.where(df['ADV20Day'] > 0, \n",
    "                                df['OnLoanQty'] / df['ADV20Day'], 0)\n",
    "    \n",
    "    df['MarketCapUSD'] = df['Float'] * df['PriceUSD']\n",
    "    \n",
    "    print(\"\\nDerived metrics calculated:\")\n",
    "    print(\"- Float (shares)\")\n",
    "    print(\"- Lendable as % of Float\")\n",
    "    print(\"- Days to Cover\")\n",
    "    print(\"- Market Capitalization\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "raw_df = load_and_prepare_data(DATA_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffa8cff",
   "metadata": {},
   "source": [
    "## Gating Framework Implementation\n",
    "\n",
    "The core gating framework that sequentially applies filters to identify the most compelling short-squeeze candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e5a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gating_framework(df):\n",
    "    \"\"\"\n",
    "    Apply the sequential gating framework to identify short-squeeze candidates.\n",
    "    Returns gate counts, analysis of dropped securities, and final filtered dataset.\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        return {}, [], pd.DataFrame()\n",
    "    \n",
    "    # Define the sequential gates\n",
    "    gates = {\n",
    "        '1. Initial Universe': lambda d: d,\n",
    "        '2. On-Loan Value >= $1M': lambda d: d[d['OnLoanValueUSD'] >= 1_000_000],\n",
    "        '3. Lendable > 10% of Float': lambda d: d[d['LendablePctFloat'] > 10],\n",
    "        '4. Utilization >= 50%': lambda d: d[d['Utilization_Pct'] >= 50],\n",
    "        '5. Days to Cover >= 2': lambda d: d[d['DaysToCover'] >= 2],\n",
    "        '6. Borrower Count >= 3': lambda d: d[d['BorrowerCount'] >= 3],\n",
    "        '7. Lender Count >= 2': lambda d: d[d['LenderCount'] >= 2]\n",
    "    }\n",
    "    \n",
    "    gate_counts = {}\n",
    "    dropped_securities_analysis = []\n",
    "    df_filtered = df.copy()\n",
    "    last_count = len(df_filtered)\n",
    "    \n",
    "    print(\"Applying gating framework...\\n\")\n",
    "    \n",
    "    for name, gate_func in gates.items():\n",
    "        df_after_gate = gate_func(df_filtered)\n",
    "        current_count = len(df_after_gate)\n",
    "        gate_counts[name] = current_count\n",
    "        \n",
    "        # Analyze dropped securities\n",
    "        if current_count < last_count:\n",
    "            dropped_indices = df_filtered.index.difference(df_after_gate.index)\n",
    "            dropped_df = df_filtered.loc[dropped_indices]\n",
    "            \n",
    "            analysis = {\n",
    "                'Gate': name,\n",
    "                'Dropped Count': last_count - current_count,\n",
    "                'Median Market Cap (M)': round(dropped_df['MarketCapUSD'].median() / 1e6, 1),\n",
    "                'Median Utilization (%)': round(dropped_df['Utilization_Pct'].median(), 1),\n",
    "                'Median Fee (bps)': round(dropped_df['AvgFee'].median(), 1)\n",
    "            }\n",
    "            dropped_securities_analysis.append(analysis)\n",
    "            \n",
    "            print(f\"{name}: {current_count:,} securities (-{last_count - current_count:,})\")\n",
    "        else:\n",
    "            print(f\"{name}: {current_count:,} securities (no change)\")\n",
    "        \n",
    "        df_filtered = df_after_gate\n",
    "        last_count = current_count\n",
    "    \n",
    "    return gate_counts, dropped_securities_analysis, df_filtered\n",
    "\n",
    "# Apply the gating framework\n",
    "if raw_df is not None:\n",
    "    gate_results, dropped_stats, final_df = apply_gating_framework(raw_df)\n",
    "    \n",
    "    initial_count = list(gate_results.values())[0]\n",
    "    final_count = list(gate_results.values())[-1]\n",
    "    reduction_pct = round(100 * (1 - final_count / initial_count), 1) if initial_count > 0 else 0\n",
    "    \n",
    "    print(f\"\\n=== SUMMARY ===\")\n",
    "    print(f\"Initial Universe: {initial_count:,} securities\")\n",
    "    print(f\"Final Candidates: {final_count:,} securities\")\n",
    "    print(f\"Reduction: {reduction_pct}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23c166b",
   "metadata": {},
   "source": [
    "## Visualization: Gating Framework Attrition\n",
    "\n",
    "Visual representation of how each gate reduces the universe of securities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398bc6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attrition_chart(gate_counts):\n",
    "    \"\"\"\n",
    "    Create a bar chart showing the attrition through each gate.\n",
    "    \"\"\"\n",
    "    labels = [label.split('. ')[1] for label in gate_counts.keys()]\n",
    "    counts = list(gate_counts.values())\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    bars = ax.bar(labels, counts, color=MAIN_COLOR, alpha=0.8)\n",
    "    \n",
    "    ax.set_ylabel('Number of Securities', fontsize=12)\n",
    "    ax.set_title('Gating Framework Attrition Analysis', fontsize=16, pad=20)\n",
    "    \n",
    "    # Remove top and right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    # Rotate x-axis labels for better readability\n",
    "    ax.tick_params(axis='x', rotation=45, labelsize=10)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2.0, yval + counts[0]*0.01, \n",
    "                f'{yval:,}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create the attrition chart\n",
    "if 'gate_results' in locals() and gate_results:\n",
    "    create_attrition_chart(gate_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29125c3",
   "metadata": {},
   "source": [
    "## Analysis of Filtered Securities\n",
    "\n",
    "Detailed analysis of the characteristics of securities dropped at each gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a239f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dropped_analysis(dropped_stats):\n",
    "    \"\"\"\n",
    "    Display analysis of securities dropped at each gate.\n",
    "    \"\"\"\n",
    "    if not dropped_stats:\n",
    "        print(\"No dropped securities analysis available.\")\n",
    "        return\n",
    "    \n",
    "    df_dropped = pd.DataFrame(dropped_stats)\n",
    "    \n",
    "    # Clean up gate names for display\n",
    "    df_dropped['Gate'] = df_dropped['Gate'].apply(lambda x: x.split('. ')[1])\n",
    "    \n",
    "    print(\"=== ANALYSIS OF FILTERED SECURITIES ===\")\n",
    "    print(\"\\nCharacteristics of securities dropped at each gate:\")\n",
    "    print(df_dropped.to_string(index=False))\n",
    "    \n",
    "    return df_dropped\n",
    "\n",
    "# Display the analysis\n",
    "if 'dropped_stats' in locals():\n",
    "    dropped_analysis_df = display_dropped_analysis(dropped_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d82241",
   "metadata": {},
   "source": [
    "## Final Candidate Analysis\n",
    "\n",
    "Detailed examination of the securities that passed all gates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c882ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_final_candidates(final_df):\n",
    "    \"\"\"\n",
    "    Analyze and display the final list of candidates that passed all gates.\n",
    "    \"\"\"\n",
    "    if final_df.empty:\n",
    "        print(\"No securities passed all gates.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"=== FINAL CANDIDATE ANALYSIS ({len(final_df)} securities) ===\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    summary_stats = {\n",
    "        'Average Utilization (%)': f\"{final_df['Utilization_Pct'].mean():.1f}\",\n",
    "        'Average Fee (bps)': f\"{final_df['AvgFee'].mean():.0f}\",\n",
    "        'Average Days to Cover': f\"{final_df['DaysToCover'].mean():.2f}\",\n",
    "        'Median Market Cap ($M)': f\"{(final_df['MarketCapUSD'].median() / 1e6):.1f}\",\n",
    "        'Average Borrower Count': f\"{final_df['BorrowerCount'].mean():.1f}\"\n",
    "    }\n",
    "    \n",
    "    for key, value in summary_stats.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Top candidates by Days to Cover\n",
    "    print(\"\\nTop 10 Candidates by Days to Cover:\")\n",
    "    display_cols = ['Ticker', 'OnLoanValueUSD', 'Utilization_Pct', 'DaysToCover', \n",
    "                   'AvgFee', 'BorrowerCount', 'LenderCount']\n",
    "    \n",
    "    top_candidates = final_df[display_cols].sort_values(by='DaysToCover', ascending=False).head(10)\n",
    "    \n",
    "    # Format for display\n",
    "    top_candidates_display = top_candidates.copy()\n",
    "    top_candidates_display['OnLoanValueUSD'] = top_candidates_display['OnLoanValueUSD'].apply(\n",
    "        lambda x: f\"${x/1e6:,.1f}M\")\n",
    "    top_candidates_display['Utilization_Pct'] = top_candidates_display['Utilization_Pct'].apply(\n",
    "        lambda x: f\"{x:.1f}%\")\n",
    "    top_candidates_display['DaysToCover'] = top_candidates_display['DaysToCover'].apply(\n",
    "        lambda x: f\"{x:.2f}\")\n",
    "    top_candidates_display['AvgFee'] = top_candidates_display['AvgFee'].apply(\n",
    "        lambda x: f\"{x:.0f} bps\")\n",
    "    \n",
    "    print(top_candidates_display.to_string(index=False))\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Analyze final candidates\n",
    "if 'final_df' in locals():\n",
    "    analyzed_final = analyze_final_candidates(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce1a7bd",
   "metadata": {},
   "source": [
    "## Distribution Analysis\n",
    "\n",
    "Visual analysis of key metrics for the final candidate list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29be5542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distribution_charts(final_df):\n",
    "    \"\"\"\n",
    "    Create distribution charts for key metrics of final candidates.\n",
    "    \"\"\"\n",
    "    if final_df.empty:\n",
    "        print(\"No data available for distribution analysis.\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Distribution Analysis of Final Candidates', fontsize=16, y=0.98)\n",
    "    \n",
    "    # Utilization distribution\n",
    "    axes[0, 0].hist(final_df['Utilization_Pct'], bins=20, color=MAIN_COLOR, alpha=0.7, edgecolor='black')\n",
    "    axes[0, 0].set_title('Utilization Distribution (%)')\n",
    "    axes[0, 0].set_xlabel('Utilization (%)')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Days to Cover distribution\n",
    "    axes[0, 1].hist(final_df['DaysToCover'], bins=20, color=MAIN_COLOR, alpha=0.7, edgecolor='black')\n",
    "    axes[0, 1].set_title('Days to Cover Distribution')\n",
    "    axes[0, 1].set_xlabel('Days to Cover')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Average Fee distribution\n",
    "    axes[1, 0].hist(final_df['AvgFee'], bins=20, color=MAIN_COLOR, alpha=0.7, edgecolor='black')\n",
    "    axes[1, 0].set_title('Average Fee Distribution (bps)')\n",
    "    axes[1, 0].set_xlabel('Average Fee (bps)')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Market Cap distribution (log scale)\n",
    "    market_cap_millions = final_df['MarketCapUSD'] / 1e6\n",
    "    axes[1, 1].hist(np.log10(market_cap_millions), bins=20, color=MAIN_COLOR, alpha=0.7, edgecolor='black')\n",
    "    axes[1, 1].set_title('Market Cap Distribution (Log Scale)')\n",
    "    axes[1, 1].set_xlabel('Log10(Market Cap $M)')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create distribution charts\n",
    "if 'final_df' in locals() and not final_df.empty:\n",
    "    create_distribution_charts(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7695b930",
   "metadata": {},
   "source": [
    "## Export Results\n",
    "\n",
    "Export the final candidate list and analysis results for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2006b705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_results(final_df, gate_results, dropped_stats):\n",
    "    \"\"\"\n",
    "    Export the analysis results to CSV files.\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "    \n",
    "    # Export final candidate list\n",
    "    if not final_df.empty:\n",
    "        final_filename = f'EquiLend_Final_Candidates_{timestamp}.csv'\n",
    "        final_df.to_csv(final_filename, index=False)\n",
    "        print(f\"Final candidates exported to: {final_filename}\")\n",
    "    \n",
    "    # Export gate analysis\n",
    "    gate_df = pd.DataFrame(list(gate_results.items()), columns=['Gate', 'Count'])\n",
    "    gate_filename = f'EquiLend_Gate_Analysis_{timestamp}.csv'\n",
    "    gate_df.to_csv(gate_filename, index=False)\n",
    "    print(f\"Gate analysis exported to: {gate_filename}\")\n",
    "    \n",
    "    # Export dropped securities analysis\n",
    "    if dropped_stats:\n",
    "        dropped_df = pd.DataFrame(dropped_stats)\n",
    "        dropped_filename = f'EquiLend_Dropped_Analysis_{timestamp}.csv'\n",
    "        dropped_df.to_csv(dropped_filename, index=False)\n",
    "        print(f\"Dropped securities analysis exported to: {dropped_filename}\")\n",
    "    \n",
    "    print(f\"\\nAll analysis completed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Export results\n",
    "if all(var in locals() for var in ['final_df', 'gate_results', 'dropped_stats']):\n",
    "    export_results(final_df, gate_results, dropped_stats)\n",
    "else:\n",
    "    print(\"Results not available for export. Please run the analysis first.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
