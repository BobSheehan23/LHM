{"cells":[{"cell_type":"code","source":["import pandas as pd\n","import docx\n","from datetime import datetime\n","import re\n","import numpy as np\n","\n","# --- Configuration ---\n","# The script will read all content from this single DOCX file.\n","CONTENT_DOC_PATH = 'daily_content.docx'\n","OUTPUT_HTML_PATH = f\"equilend_daily_digest_{datetime.now().strftime('%Y_%m_%d')}.html\"\n","\n","# --- 1. DOCX Content and Table Parsing ---\n","\n","def parse_docx_tables_from_text(paras):\n","    \"\"\"\n","    Finds and parses tables that are pasted as plain text in the .docx file.\n","\n","    It identifies table sections by their text headers and parses the subsequent\n","    comma-separated lines.\n","\n","    Args:\n","        paras (list): A list of all paragraph texts from the document.\n","\n","    Returns:\n","        tuple: A tuple containing the HTML for the two table bodies.\n","    \"\"\"\n","    ht_borrow_html = \"\"\n","    squeeze_html = \"\"\n","\n","    def format_change(value, unit=' BPS'):\n","        try:\n","            # Clean the value by removing commas and whitespace before converting to float\n","            cleaned_value = str(value).replace(',', '').strip()\n","            val = float(cleaned_value)\n","            color = '#16a34a' if val > 0 else '#dc2626'\n","            sign = '+' if val > 0 else ''\n","            # Format as integer since the new data doesn't have decimals for this field\n","            return f'<span style=\"color:{color}; font-size:14px;\">{sign}{val:,.0f}{unit}</span>'\n","        except (ValueError, TypeError):\n","            return str(value).strip() if pd.notna(value) else ''\n","\n","    # --- Find and Parse \"Hot & Getting Hotter\" Table ---\n","    try:\n","        ht_start_index = -1\n","        for i, p_text in enumerate(paras):\n","            if \"hot & getting hotter\" in p_text.lower():\n","                ht_start_index = i + 1 # Data starts after the header\n","                break\n","\n","        if ht_start_index != -1:\n","            header = [h.strip() for h in paras[ht_start_index].split(',')]\n","            header_map = {h: i for i, h in enumerate(header)}\n","\n","            for i in range(ht_start_index + 1, len(paras)):\n","                line = paras[i]\n","                if not line or \"market technicals\" in line.lower():\n","                    break\n","\n","                cells = [cell.strip().replace('\"', '') for cell in line.split(',')]\n","                if len(cells) < len(header): continue\n","\n","                ht_borrow_html += f\"\"\"\n","                <tr style=\"font-size:12px; background-color:#ffffff; text-align:left;\">\n","                    <td style=\"padding:4px 8px;\">{cells[header_map['TICKER']]}</td>\n","                    <td style=\"padding:4px 8px;\">{cells[header_map['Company Name']]}</td>\n","                    <td style=\"padding:4px 8px;\">{cells[header_map['Industry']]}</td>\n","                    <td style=\"padding:4px 8px;\">{cells[header_map['Price']]}</td>\n","                    <td style=\"padding:4px 8px;\">{cells[header_map['Fee Band']]}</td>\n","                    <td style=\"padding:4px 8px;\">{format_change(cells[header_map['Fee Wk Diff (BPS)']])}</td>\n","                </tr>\"\"\"\n","    except Exception as e:\n","        print(f\"Warning: Could not parse 'Hot & Getting Hotter' table from text. Error: {e}\")\n","\n","    # --- Find and Parse \"Squeeze Metrics\" Table ---\n","    try:\n","        sq_start_index = -1\n","        for i, p_text in enumerate(paras):\n","            if \"market technicals & squeeze metrics\" in p_text.lower():\n","                sq_start_index = i + 1\n","                break\n","\n","        if sq_start_index != -1:\n","            header = [h.strip() for h in paras[sq_start_index].split(',')]\n","            header_map = {h: i for i, h in enumerate(header)}\n","\n","            for i in range(sq_start_index + 1, len(paras)):\n","                line = paras[i]\n","                if not line or \"key takeaways\" in line.lower():\n","                    break\n","\n","                cells = [cell.strip().replace('\"', '') for cell in line.split(',')]\n","                if len(cells) < len(header): continue\n","\n","                squeeze_html += f\"\"\"\n","                <tr style=\"font-size:12px; background-color:#ffffff; text-align:left;\">\n","                    <td style=\"padding:4px 8px;\">{cells[header_map['TICKER']]}</td>\n","                    <td style=\"padding:4px 8px;\">{cells[header_map['Company Name']]}</td>\n","                    <td style=\"padding:4px 8px;\">{cells[header_map['Industry']]}</td>\n","                    <td style=\"padding:4px 8px;\">{cells[header_map['Price']]}</td>\n","                    <td style=\"padding:4px 8px;\">{cells[header_map['SSS']]}</td>\n","                    <td style=\"padding:4px 8px;\">{format_change(cells[header_map['SSS Week Diff']], unit=\"\")}</td>\n","                </tr>\"\"\"\n","    except Exception as e:\n","        print(f\"Warning: Could not parse Squeeze Metrics table from text. Error: {e}\")\n","\n","    return ht_borrow_html, squeeze_html\n","\n","\n","def parse_daily_content(doc_path):\n","    \"\"\"\n","    Parses the .docx file for all text content, including market notes, headlines, and key takeaways.\n","    \"\"\"\n","    try:\n","        document = docx.Document(doc_path)\n","    except Exception as e:\n","        print(f\"Error opening or parsing DOCX file: {e}\")\n","        return None, []\n","\n","    content = {'market_notes': {}, 'headlines': [], 'key_takeaways': []}\n","    paras = [p.text.strip() for p in document.paragraphs if p.text.strip()]\n","\n","    # --- Parse Market Notes ---\n","    try:\n","        # Find all bullet points after \"Market Notes:\"\n","        market_notes_idx = -1\n","        for i, p_text in enumerate(paras):\n","            if 'market notes' in p_text.lower():\n","                market_notes_idx = i\n","                break\n","\n","        if market_notes_idx != -1:\n","            # Find all subsequent bullet points\n","            for i in range(market_notes_idx + 1, len(paras)):\n","                line = paras[i]\n","                if not line.startswith('*'): break # Stop when we run out of bullet points\n","\n","                line = line.lstrip('* ').strip()\n","                if 'Average Fee:' in line:\n","                    match = re.search(r'(\\d+\\.?\\d*)\\s*bps\\s*([+-]?\\d+\\.?\\d*)%', line)\n","                    if match:\n","                        content['market_notes']['avg_fee_bps'] = match.group(1)\n","                        content['market_notes']['avg_fee_change'] = float(match.group(2))\n","                elif 'Average Utilization:' in line:\n","                    match = re.search(r'(\\d+\\.?\\d*)%\\s*([+-]?\\d+\\.?\\d*)%', line)\n","                    if match:\n","                        content['market_notes']['avg_util_percent'] = match.group(1)\n","                        content['market_notes']['avg_util_change'] = float(match.group(2))\n","                elif 'On Loan Value:' in line:\n","                    match = re.search(r'(\\d+\\.?\\d*T)\\s*([+-]?\\d+\\.?\\d*)%', line)\n","                    if match:\n","                        content['market_notes']['on_loan_value'] = match.group(1)\n","                        content['market_notes']['on_loan_value_change'] = float(match.group(2))\n","                elif 'Total Lendable Value:' in line:\n","                    match = re.search(r'(\\d+\\.?\\d*T)\\s*([+-]?\\d+\\.?\\d*)%', line)\n","                    if match:\n","                        content['market_notes']['lendable_value'] = match.group(1)\n","                        content['market_notes']['lendable_value_change'] = float(match.group(2))\n","    except (ValueError, IndexError) as e:\n","        print(f\"Warning: Could not parse Market Notes. Check document structure. Error: {e}\")\n","\n","    # --- Parse Headlines ---\n","    try:\n","        headline_start_index = -1\n","        for i, p_text in enumerate(paras):\n","            if 'major headlines' in p_text.lower():\n","                headline_start_index = i + 1\n","                break\n","\n","        if headline_start_index != -1:\n","            i = headline_start_index\n","            while len(content['headlines']) < 3 and i < len(paras):\n","                end_of_block_idx = -1\n","                for j in range(i, len(paras)):\n","                    if 'what our data shows' in paras[j].lower() or 'what our data is saying' in paras[j].lower():\n","                        end_of_block_idx = j\n","                        break\n","\n","                if end_of_block_idx != -1:\n","                    title = paras[i].rstrip(':').rstrip('.')\n","                    description = \"\\n\".join(paras[i+1:end_of_block_idx])\n","                    data_insight_raw = paras[end_of_block_idx]\n","                    data_insight = re.sub(r'[\\*•\\s]*What our data (shows|is saying):\\s?', '', data_insight_raw, flags=re.IGNORECASE).strip()\n","\n","                    content['headlines'].append({\n","                        'title': title,\n","                        'description': description,\n","                        'data_insight': data_insight\n","                    })\n","                    i = end_of_block_idx + 1\n","                else:\n","                    break\n","    except (ValueError, IndexError) as e:\n","        print(f\"Warning: Could not parse Headlines. Check document structure. Error: {e}\")\n","\n","    # --- Parse Key Takeaways ---\n","    try:\n","        takeaways_start_index = -1\n","        for i, p_text in enumerate(paras):\n","            if 'key takeaways' in p_text.lower():\n","                takeaways_start_index = i + 1\n","                break\n","        if takeaways_start_index != -1:\n","            for i in range(takeaways_start_index, len(paras)):\n","                line = paras[i]\n","                if not line: break # Stop at blank line\n","                content['key_takeaways'].append(line)\n","    except (ValueError, IndexError) as e:\n","        print(f\"Warning: Could not parse Key Takeaways. Check document structure. Error: {e}\")\n","\n","    return content, paras\n","\n","# --- 2. HTML Generation ---\n","\n","def create_digest_html(content, table_html_tuple):\n","    \"\"\"\n","    Generates the final HTML for the digest by populating a template.\n","    \"\"\"\n","    if not content:\n","        return \"<h1>Error: Could not parse content from DOCX file.</h1>\"\n","\n","    ht_borrow_table, squeeze_table = table_html_tuple\n","\n","    def format_market_note_change(value):\n","        color = '#16a34a' if value > 0 else '#dc2626'\n","        sign = '+' if value > 0 else ''\n","        return f'<span style=\"color:{color}; font-size:14px;\">{sign}{value:.2f}%</span>'\n","\n","    market_notes = content.get('market_notes', {})\n","    avg_fee_bps = market_notes.get('avg_fee_bps', 'N/A')\n","    avg_fee_change = format_market_note_change(market_notes.get('avg_fee_change', 0))\n","    avg_util_percent = market_notes.get('avg_util_percent', 'N/A')\n","    avg_util_change = format_market_note_change(market_notes.get('avg_util_change', 0))\n","    on_loan_value = market_notes.get('on_loan_value', 'N/A')\n","    on_loan_value_change = format_market_note_change(market_notes.get('on_loan_value_change', 0))\n","    lendable_value = market_notes.get('lendable_value', 'N/A')\n","    lendable_value_change = format_market_note_change(market_notes.get('lendable_value_change', 0))\n","\n","    headlines_html = \"\"\n","    for headline in content.get('headlines', []):\n","        headlines_html += f\"\"\"\n","        <div style=\"margin-top:20px;\">\n","            <strong style=\"font-size:16px;\">{headline['title']}</strong>\n","            <p style=\"margin:5px 0 0; white-space: pre-wrap;\">{headline['description']}</p>\n","            <ul style=\"margin:10px 0 0; padding-left:20px; color:#334155; list-style-type: disc;\">\n","              <li><strong>What Our Data Shows:</strong> {headline['data_insight']}</li>\n","            </ul>\n","        </div>\n","        \"\"\"\n","\n","    takeaways_html = \"\".join([f\"<li>{item}</li>\" for item in content.get('key_takeaways', [])])\n","\n","    html_template = f\"\"\"\n","<!DOCTYPE html>\n","<html lang=\"en\">\n","<head>\n","  <meta charset=\"UTF-8\">\n","  <title>EquiLend D&A Daily Digest - {datetime.now().strftime('%B %d, %Y')}</title>\n","</head>\n","<body style=\"margin:0; padding:0; font-family: Arial, sans-serif; background-color:#f1f5f9;\">\n","  <table width=\"100%\" cellpadding=\"0\" cellspacing=\"0\" border=\"0\" bgcolor=\"#f1f5f9\">\n","    <tr>\n","      <td align=\"center\">\n","        <table width=\"800\" cellpadding=\"0\" cellspacing=\"0\" border=\"0\" bgcolor=\"#ffffff\" style=\"margin:20px 0; border-radius:4px; overflow:hidden;\">\n","          <!-- Header -->\n","          <tr>\n","            <td bgcolor=\"#0284c7\" style=\"padding:20px; text-align:center;\">\n","              <h1 style=\"margin:0; font-size:24px; color:#ffffff;\">EquiLend D&amp;A Daily Digest</h1>\n","              <p style=\"margin:5px 0 0; font-size:16px; color:#bae6fd;\">{datetime.now().strftime('%B %d, %Y')}</p>\n","            </td>\n","          </tr>\n","          <!-- Content -->\n","          <tr>\n","            <td style=\"padding:20px; color:#333333; font-size:14px; line-height:1.5;\">\n","\n","              <!-- Market Notes -->\n","              <h2 style=\"font-size:18px; margin-bottom:10px; color:#0284c7;\">&#x1F4BC; Market Notes</h2>\n","              <table width=\"100%\" cellpadding=\"5\" cellspacing=\"0\" border=\"0\" bgcolor=\"#f8fafc\" style=\"margin-bottom:20px;\">\n","                <tr>\n","                  <td align=\"center\" width=\"50%\">\n","                    <p style=\"margin:0; font-size:12px; color:#64748b;\">Average Fee</p>\n","                    <p style=\"margin:5px 0 0; font-size:18px; font-weight:bold; color:#334155;\">\n","                      {avg_fee_bps} bps {avg_fee_change}\n","                    </p>\n","                  </td>\n","                  <td align=\"center\" width=\"50%\">\n","                    <p style=\"margin:0; font-size:12px; color:#64748b;\">Average Utilization</p>\n","                    <p style=\"margin:5px 0 0; font-size:18px; font-weight:bold; color:#334155;\">\n","                      {avg_util_percent}% {avg_util_change}\n","                    </p>\n","                  </td>\n","                </tr>\n","                <tr>\n","                  <td align=\"center\" width=\"50%\">\n","                    <p style=\"margin:0; font-size:12px; color:#64748b;\">On Loan Value</p>\n","                    <p style=\"margin:5px 0 0; font-size:18px; font-weight:bold; color:#334155;\">\n","                      ${on_loan_value} {on_loan_value_change}\n","                    </p>\n","                  </td>\n","                  <td align=\"center\" width=\"50%\">\n","                    <p style=\"margin:0; font-size:12px; color:#64748b;\">Total Lendable Value</p>\n","                    <p style=\"margin:5px 0 0; font-size:18px; font-weight:bold; color:#334155;\">\n","                      ${lendable_value} {lendable_value_change}\n","                    </p>\n","                  </td>\n","                </tr>\n","              </table>\n","\n","              <!-- Headlines -->\n","              <h2 style=\"font-size:18px; margin-bottom:10px; color:#0284c7;\">&#x1F4F0; Major Headlines and What Our Data Shows</h2>\n","              {headlines_html}\n","\n","              <!-- Tables Section -->\n","              <h2 style=\"font-size:18px; margin:20px 0 10px; color:#0284c7;\">&#x1F525; Hot & Getting Hotter</h2>\n","              <table cellpadding=\"0\" cellspacing=\"0\" border=\"1\" style=\"border-collapse:collapse; margin-bottom:20px; border-color:#dddddd; font-size:12px;\" width=\"100%\">\n","                <thead>\n","                  <tr bgcolor=\"#0284c7\" style=\"color:#ffffff; font-weight:bold; text-align:left;\">\n","                    <th style=\"padding:5px 8px; white-space: nowrap;\">Ticker</th>\n","                    <th style=\"padding:5px 8px; white-space: nowrap;\">Company Name</th>\n","                    <th style=\"padding:5px 8px; white-space: nowrap;\">Industry</th>\n","                    <th style=\"padding:5px 8px; white-space: nowrap;\">Price</th>\n","                    <th style=\"padding:5px 8px; white-space: nowrap;\">Fee Band</th>\n","                    <th style=\"padding:5px 8px; white-space: nowrap;\">Fee Wk Diff (BPS)</th>\n","                  </tr>\n","                </thead>\n","                <tbody>\n","                  {ht_borrow_table}\n","                </tbody>\n","              </table>\n","\n","              <h2 style=\"font-size:18px; margin:20px 0 10px; color:#0284c7;\">&#x1F52C; Market Technicals & Squeeze Metrics</h2>\n","              <table cellpadding=\"0\" cellspacing=\"0\" border=\"1\" style=\"border-collapse:collapse; border-color:#dddddd; font-size:12px;\" width=\"100%\">\n","                <thead>\n","                  <tr bgcolor=\"#0284c7\" style=\"color:#ffffff; font-weight:bold; text-align:left;\">\n","                    <th style=\"padding:5px 8px; white-space: nowrap;\">Ticker</th>\n","                    <th style=\"padding:5px 8px; white-space: nowrap;\">Company Name</th>\n","                    <th style=\"padding:5px 8px; white-space: nowrap;\">Industry</th>\n","                    <th style=\"padding:5px 8px; white-space: nowrap;\">Price</th>\n","                    <th style=\"padding:5px 8px; white-space: nowrap;\">SSS</th>\n","                    <th style=\"padding:5px 8px; white-space: nowrap;\">SSS Week Diff</th>\n","                  </tr>\n","                </thead>\n","                <tbody>\n","                  {squeeze_table}\n","                </tbody>\n","              </table>\n","\n","              <!-- Key Takeaways -->\n","              <h2 style=\"font-size:18px; margin:20px 0 10px; color:#0284c7;\">&#x1F4A1; Key Takeaways</h2>\n","              <ul style=\"padding-left:20px; color:#334155; font-size:14px; margin:0;\">\n","                {takeaways_html}\n","              </ul>\n","\n","            </td>\n","          </tr>\n","          <!-- Footer -->\n","          <tr>\n","            <td align=\"center\" style=\"padding:10px; font-size:12px; color:#64748b;\">\n","              Source: EquiLend Data &amp; Analytics\n","            </td>\n","          </tr>\n","        </table>\n","      </td>\n","    </tr>\n","  </table>\n","</body>\n","</html>\n","    \"\"\"\n","    return html_template\n","\n","# --- Main Execution ---\n","if __name__ == \"__main__\":\n","    print(\"Starting daily digest generation...\")\n","\n","    # 1. Parse all content from the Word document\n","    print(f\"Reading all content from '{CONTENT_DOC_PATH}'...\")\n","    parsed_content, all_paras = parse_daily_content(CONTENT_DOC_PATH)\n","\n","    # 2. Parse the tables from the text paragraphs\n","    print(\"Parsing tables from the Word document text...\")\n","    table_html = parse_docx_tables_from_text(all_paras)\n","\n","    # 3. Generate the final HTML file\n","    print(\"Generating final HTML digest...\")\n","    final_html = create_digest_html(parsed_content, table_html)\n","\n","    # 4. Save the HTML to a file\n","    with open(OUTPUT_HTML_PATH, 'w', encoding='utf-8') as f:\n","        f.write(final_html)\n","\n","    print(f\"\\nSuccessfully generated digest: {OUTPUT_HTML_PATH}\")\n","    if not parsed_content.get('headlines'):\n","        print(\"\\nWARNING: No headlines were parsed. Please check the 'Major Headlines' section in your .docx file for correct formatting.\")\n","    if not table_html[0] and not table_html[1]:\n","        print(\"\\nWARNING: No tables were found or parsed from the Word document. Please ensure they are pasted as plain text and not images.\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Starting daily digest generation...\n","Reading all content from 'daily_content.docx'...\n","Parsing tables from the Word document text...\n","Generating final HTML digest...\n","\n","Successfully generated digest: equilend_daily_digest_2025_07_23.html\n","\n","WARNING: No headlines were parsed. Please check the 'Major Headlines' section in your .docx file for correct formatting.\n","\n","WARNING: No tables were found or parsed from the Word document. Please ensure they are pasted as plain text and not images.\n"]}],"execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P2xQHvRMaXoI","executionInfo":{"status":"ok","timestamp":1753276413431,"user_tz":240,"elapsed":123,"user":{"displayName":"Bob Sheehan","userId":"08159093702253523584"}},"outputId":"82506f8f-1106-440f-c263-ca81c2ba985f"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"642e8c69","executionInfo":{"status":"ok","timestamp":1753276383433,"user_tz":240,"elapsed":10341,"user":{"displayName":"Bob Sheehan","userId":"08159093702253523584"}},"outputId":"7aab118a-16c9-4b20-897d-74f25f5d42cc"},"source":["%pip install python-docx"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting python-docx\n","  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n","Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n","Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.14.1)\n","Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/253.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m245.8/253.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: python-docx\n","Successfully installed python-docx-1.2.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70d7b68e","executionInfo":{"status":"ok","timestamp":1753276726133,"user_tz":240,"elapsed":13,"user":{"displayName":"Bob Sheehan","userId":"08159093702253523584"}},"outputId":"ad3fd868-591e-43f7-8fbb-116da67cdce1"},"source":["import docx\n","\n","doc_path = 'daily_content.docx'\n","\n","try:\n","    document = docx.Document(doc_path)\n","    print(f\"--- Content of {doc_path} ---\")\n","    for i, paragraph in enumerate(document.paragraphs):\n","        print(f\"Paragraph {i+1}: {paragraph.text}\")\n","except Exception as e:\n","    print(f\"Error reading DOCX file: {e}\")"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Content of daily_content.docx ---\n","Paragraph 1: Market Notes:\n","Paragraph 2: * Average Fee: 45.2 bps -0.24%\n","Paragraph 3: * Average Utilization: 7.03% 1.37%\n","Paragraph 4: \n","Paragraph 5: Major Headlines & What Our Data Shows:\n","Paragraph 6: **Trump Discusses Firing Fed boss** In the latest of the ongoing tension between the US President and Federal Reserve Chair, Jerome Powell, reports emerged from the White House that Trump was planning to remove Powell but Trump has since responded and claimed that it is ‘highly unlikely’ that he will. The focal point to this conflict is the contrast in approach to interest rates, with Trump searching for a 300bps reduction from the conservative 4% set by Powell.\n","Paragraph 7: Data:  A notable rise in loaned shares across the U.S. Financials sector could be signaling growing investor caution regarding potential changes at the Federal Reserve. Our data shows a net increase of over 50 million shares on loan for U.S. financial companies over the past week. This may be an indication that some investors are worried about an abrupt change in the chairman role, and in turn, policy setting.  \n","Paragraph 8: **Samsung boss cleared of Fraud Charges** Samsung boss Lee Jae-Yong has been cleared of fraud charges by South Korea’s top court following a 5-year trial process. This comes following his role in a merger deal in 2015, where there were accusations of inflating the value of his pharmaceutical firm.\n","Paragraph 9: Data: Our data shows limited lending effects due to this trial. However, in the past months the tariff turbulence has significantly affected Samsung SDI, the battery and electronic materials manufacturing branch of the Korean tech giant. Since the tariff announcement on April 2nd, On Loan Quantity has risen significantly (over 2000% from the months prior). In Q2 2025, On Loan Quantity averaged 1.21 million shares, up 4777% YoY, and borrowing costs rose 95% YoY to 44.92 bps showing a significant increase in borrower interest in the stock.\n","Paragraph 10: **Layoff Wave Hits Multiple Sectors, AI Reshaping Workforce** 2025 is seeing widespread job cuts across sectors, with firms like Intel, Meta, Microsoft, and Chevron announcing thousands of layoffs. A key cause of this has been AI, with over 40% of companies expecting further workforce reductions by 2030. Still, areas like fintech and big data are seeing growth, creating a realignment in employment patterns.\n","Paragraph 11: Data: Many AI firms are blooming in the wake of job cuts elsewhere, with one of the latest companies highlighted by EquiLend’s Data & Analytics being Quantum Computing Inc (QUBT). The borrowing cost of the AI firm has been extremely volatile since November last year, with an 11,000-bps peak in early January. On Loan Quantity has also risen over this time from under 5 million shares on loan in mid-November last year to peaks of over 35 million shares this month.\n","Paragraph 12: \n","Paragraph 13: Key Takeaways:\n","Paragraph 14: Markets stabilize after Trump Fed drama with Treasury Yields and the dollar rebounding. However, there may be concerns about an abrupt change in monetary policy.\n","Paragraph 15: AI continues to be a point of focus both for companies and investors. Tech earnings are underway with AI driving strong Q2 results for many tech giants.\n","Paragraph 16: Inflation remains a hot topic globally with the latest rises seen in the UK and debate still ongoing in the US.\n","Paragraph 17: \n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}